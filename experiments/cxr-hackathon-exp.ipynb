{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85396,"databundleVersionId":9645513,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os, shutil\nimport cv2\nimport skimage\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Define the directory containing the images\ndir_path = '/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/processed_train_data'\n\n# List all files in the directory\nimg_files = os.listdir(dir_path)\n\ndf_metadata = pd.read_csv(\"/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/1. train_metadata.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Displaying the data\nplt.figure(figsize=(20,10))\n\nfor i in range(9):\n    plt.subplot(3,3,i+1)\n    img_path = os.path.join(dir_path, img_files[i])\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.axis(\"off\")\n    plt.title(\"Title\")\nplt.tight_layout()\nplt.show()\n\n# It is evident from the below images, they are in different sizes.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Explore distribution - understand the data\ndf_metadata.tail(5)\ndf_metadata.nunique()\n\n# We have 2 classes present -> pneumonia and healthy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2a. Plot the class distribution\nclass_counts = df_metadata['class'].value_counts()\nclass_counts.plot(kind='bar', figsize=(20, 6))\nplt.title('Class Distribution')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.show()\n\n#There is an imbalance in the dataset, we have more samples in pnemonia class than in healthy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3a. Pre-processing \n# Resizing, Color Space, Input construction (what to give as an input?)\n# Helper Functions - If we make use of ImageDataGenerator and flow_from_directory, we have inbuilt capabilities\n\ndef resize_image(image, size=(224, 224)):\n    return cv2.resize(image, size)\n\ndef normalize_image(image):\n    return image / 255.0\n\ndef convert_color_space(image, color_space='gray'):\n    if color_space == 'gray':\n        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    elif color_space == 'rgb':\n        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    else:\n        raise ValueError(\"Unsupported color space\")\n\ndef preprocess_images(image_paths, size=(224, 224), color_space='gray'):\n    preprocessed_images = []\n    for image_path in image_paths:\n        image = preprocess_image(image_path, size, color_space)\n        preprocessed_images.append(image)\n    return np.array(preprocessed_images)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the paths\n# Create and copy healthy and pneumonia images to working dir in kaggle \nbase_dir = '/kaggle/working/processed_train_data'\nhealthy_dir = os.path.join(base_dir, 'healthy')\npneumonia_dir = os.path.join(base_dir, 'pneumonia')\n\n# Create directories if they don't exist\nos.makedirs(healthy_dir, exist_ok=True)\nos.makedirs(pneumonia_dir, exist_ok=True)\n\n# Load the metadata file\nmetadata_file = '/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/1. train_metadata.csv'\nmetadata = pd.read_csv(metadata_file)\n\n# Source directory where images are currently stored\nsource_dir = '/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/processed_train_data'\n\n# Iterate through the metadata and move images\nfor index, row in metadata.iterrows():\n    img_name = row['path']\n    img_class = row['class']\n    \n    if img_class == 'healthy':\n        shutil.copy(os.path.join(source_dir, img_name), os.path.join(healthy_dir, img_name))\n    elif img_class == 'pneumonia':\n        shutil.copy(os.path.join(source_dir, img_name), os.path.join(pneumonia_dir, img_name))\n\nprint(\"Images have been copied successfully!\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3b. Synthetic Data Generation\n# ImageDataGenerator helps in DataTransformation/Augmentation, Normalization/Scaling\n# We can also make use of validation_split to generate train and validation sets\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.25,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    rescale=1./255,\n    validation_split=0.2\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3c. Data composition into tf format \n#  The method expects a specific directory structure where images are organized into subdirectories, \n#  each representing a class. This is an important note. Also subset='training/validation'\n\ntrain_dir ='/kaggle/working/processed_train_data'\n\ntrain_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),  # Resize images to 224x224, Default is 256x256\n    batch_size=32, #default is 32\n    class_mode='binary', # Possible values are categorical, binary, sparse, input, None\n#     color_mode='grayscale', # rgb, rgba, grayscale\n    shuffle=True,\n    seed=42,\n    subset='training'\n    \n)\n\n\nvalidation_generator = datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n#     color_mode='grayscale',\n    shuffle=False,\n    seed=42,\n    subset='validation'\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Any other relevant pre-processing (upto your exploration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Development","metadata":{}},{"cell_type":"code","source":"# 1. Divide into train and test (can be done in the model.fit too)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Define Model \n# Define the CNN model\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install tensorflow-addons","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Define model compilation requirements - optimizer, loss, early stopping, etc. \n\n# We don't have any direct metric f1_score in tf.keras.metric, so need to get from add-on\n#import tensorflow_addons as tfa\n#f1_score = tfa.metrics.F1Score(num_classes=1, threshold=0.5)\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. Enable tensorboard for tracking\nfrom tensorflow.keras.callbacks import TensorBoard\nimport datetime\nlog_dir = \"/kaggle/working/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint_dir = \"/kaggle/working/checkpoints\"\ncheckpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_dir + \"/model-{epoch:02d}-{val_loss:.2f}.keras\",\n    save_weights_only=False, #if True only weights will be saved, then it must be .h5 extn\n    save_best_only=True,\n    monitor='val_loss',\n    mode='min',\n    verbose=1\n)\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nearly_stopping_callback = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    mode='min',\n    verbose=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Adding class weight to \nfrom sklearn.utils.class_weight import compute_class_weight\ny_train = train_generator.classes\nclass_weights = compute_class_weight(class_weight='balanced',classes=np.unique(y_train), y=y_train)\nclass_weight_dict = dict(enumerate(class_weights))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Fit Model; make sure to save checkpoints at intermediate points to avoid loss of information\n### Experiment with different models and design\n\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // validation_generator.batch_size,\n    epochs=50,\n    callbacks=[tensorboard_callback,checkpoint_callback,early_stopping_callback],\n    class_weight=class_weight_dict\n)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seems like there is an issue with Kaggle while loading tensorboard\n# Search for \"kkb-production.jupyter-proxy.kaggle.net took too long to respond\"\n%reload_ext tensorboard\n%tensorboard --logdir /kaggle/working/logs/fit/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Evaluate with relevant metric for your problem. \n\n# Evaluate the model on the validation data\nloss, accuracy = model.evaluate(validation_generator)\nprint(f'Validation Test Loss: {loss}')\nprint(f'Validation Test Accuracy: {accuracy * 100:.2f}%')\n#print(f'Validation Test F1 Score: {f1_score:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. After model choice is made, fine-tune model - hyperparameters!","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning Using Xception","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n\n# Load the pre-trained Xception model\nbase_model_xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of the base model\nx = base_model_xception.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\npredictions = Dense(1, activation='sigmoid')(x)  # For binary classification\n\n# Create the final model\nmodel_tf_xception = Model(inputs=base_model_xception.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model_xception.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel_tf_xception.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Data generators\n#train_datagen = ImageDataGenerator(rescale=1./255)\n#train_generator = train_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n#validation_datagen = ImageDataGenerator(rescale=1./255)\n#validation_generator = validation_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n# Train the model\nhistory_tf_xception = model_tf_xception.fit(train_generator, epochs=10, validation_data=validation_generator, class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Unfreeze some layers of the base model\nfor layer in base_model_xception.layers[-5:]:  # Unfreeze the last 5 layers\n    layer.trainable = True\n\n# Compile the model with a lower learning rate\nmodel_tf_xception.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Continue training the model with fine-tuning\nhistory_fine_exception = model_tf_xception.fit(train_generator, epochs=10, validation_data=validation_generator,class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Evaluate the model on the validation data\nloss, accuracy = model_tf_xception.evaluate(validation_generator)\nprint(f'Validation Test Loss: {loss}')\nprint(f'Validation Test Accuracy: {accuracy * 100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning using ResNet50","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\n\n\n# Load the pre-trained ResNet50 model\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of the base model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n\nx = Dense(2048, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.2)(x)\n\nx = Dense(1024, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.2)(x)\n\nx = Dense(512, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.2)(x)\n\npredictions = Dense(1, activation='sigmoid')(x)  # For binary classification\n\n# Create the final model\nmodel_tf = Model(inputs=base_model.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel_tf.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Data generators\n#train_datagen = ImageDataGenerator(rescale=1./255)\n#train_generator = train_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n#validation_datagen = ImageDataGenerator(rescale=1./255)\n#validation_generator = validation_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n# Train the model\nhistory_tf = model_tf.fit(train_generator, epochs=10, validation_data=validation_generator, class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Unfreeze some layers of the base model\nfor layer in base_model.layers[-5:]:  # Unfreeze the last 5 layers\n    layer.trainable = True\n\n# Compile the model with a lower learning rate\nmodel_tf.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Continue training the model with fine-tuning\nhistory_fine = model_tf.fit(train_generator, epochs=10, validation_data=validation_generator,class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Learning using VGG16","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Nadam\n\n\n# Load the pre-trained VGG16 model\nbase_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Add custom layers on top of the base model\nx = base_model_vgg16.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(512, activation='relu')(x)\npredictions = Dense(1, activation='sigmoid')(x)  # For binary classification\n\n# Create the final model\nmodel_tf_vgg16 = Model(inputs=base_model_vgg16.input, outputs=predictions)\n\n# Freeze the base model layers\nfor layer in base_model_vgg16.layers:\n    layer.trainable = False\n\n# Compile the model\nmodel_tf_vgg16.compile(optimizer=Nadam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Data generators\n#train_datagen = ImageDataGenerator(rescale=1./255)\n#train_generator = train_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n#validation_datagen = ImageDataGenerator(rescale=1./255)\n#validation_generator = validation_datagen.flow_from_directory('/kaggle/working/processed_train_data', target_size=(224, 224), batch_size=32, class_mode='binary')\n\n# Train the model\nhistory_tf_vgg16 = model_tf_vgg16.fit(train_generator, epochs=10, validation_data=validation_generator, class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Nadam\n\n# Unfreeze some layers of the base model\nfor layer in base_model_vgg16.layers[-5:]:  # Unfreeze the last 5 layers\n    layer.trainable = True\n\n# Compile the model with a lower learning rate\nmodel_tf_vgg16.compile(optimizer=Nadam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Continue training the model with fine-tuning\nhistory_fine_vgg16 = model_tf_vgg16.fit(train_generator, epochs=10, validation_data=validation_generator,class_weight=class_weight_dict, callbacks=[checkpoint_callback,early_stopping_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model_tf_vgg16.evaluate(validation_generator)\nprint(f'Validation Test Loss: {loss}')\nprint(f'Validation Test Accuracy: {accuracy * 100:.2f}%')\n#print(f'Validation Test F1 Score: {f1_score:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ensemble Learning","metadata":{}},{"cell_type":"code","source":"def ensemble_predictions(models, data):\n    predictions = [model.predict(data) for model in models]\n    predictions = np.array(predictions)\n    avg_predictions = np.mean(predictions, axis=0)\n    return avg_predictions\n\n# List of models\nmodels = [model_tf_vgg16, model_tf, model]\n\n# Get ensemble predictions\nensemble_preds = ensemble_predictions(models, validation_generator)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\n# Convert predictions to binary labels\nensemble_labels = (ensemble_preds > 0.5).astype(int)\n\n# True labels\ntrue_labels = validation_generator.classes\n\n# Evaluate performance\naccuracy = accuracy_score(true_labels, ensemble_labels)\nf1 = f1_score(true_labels, ensemble_labels)\n\nprint(f'Ensemble Model Accuracy: {accuracy}')\nprint(f'Ensemble Model F1 Score: {f1}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing and Creating Output","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\n# Create the directory structure - Prepare the test directory in kaggle/working\ntestdata = '/kaggle/working/testdata/images'\nos.makedirs(testdata, exist_ok=True)\n\n# Define source and destination directories\nsource_dir = '/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/processed_test_set'\ndestination_dir = testdata\n\n# Copy files from source to destination\nfor filename in os.listdir(source_dir):\n    src_file = os.path.join(source_dir, filename)\n    dst_file = os.path.join(destination_dir, filename)\n    shutil.copy(src_file, dst_file)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating output file for submission - Template Code\ntest_pd = pd.read_csv('/kaggle/input/123-of-ai-presents-pneumonia-detection-from-xray/2. test_files.csv')\n\n# Do the same pre-processing/formatting as the training set for the test set - remember to use batch_size 1 for testing\ntest_data_dir = '/kaggle/working/testdata/'\ntest_datagen = ImageDataGenerator(rescale=1./255) #No augmentation needed for test :)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(224, 224),\n    batch_size=1,      # Process one by one\n    class_mode=None,   # No labels for test data, so None\n    shuffle=False      # Preserve the order for test\n)\n\nif test_generator.samples == 0:\n    raise ValueError(\"The test_generator is empty. Please check the directory structure and paths.\")\n\n# Evaluate trained model on test set - Load your trained model\n#model = tf.keras.models.load_model('/kaggle/working/checkpoints/model-05-0.30.keras')\n#predictions = model.predict(test_generator)\n#y_pred = np.where(predictions > 0.5, 1, 0).flatten()\n\n# Evaluate on TF+FineTuned model\n#model_tf_i = tf.keras.models.load_model('/kaggle/working/checkpoints/model-02-0.23.keras')\npredictions = model_tf.predict(test_generator)\ny_pred = np.where(predictions > 0.5, 1, 0).flatten()\n\n#Ensemble\n#vgg16_preds = model_tf_vgg16.predict(test_generator)\n#resnet50_preds = model_tf.predict(test_generator)\n#cnn_preds = model.predict(test_generator)\n\n# Ensemble the predictions\n#ensemble_preds = (vgg16_preds + resnet50_preds + cnn_preds) / 3\n#ensemble_labels = (ensemble_preds > 0.5).astype(int)\n#y_pred = ensemble_labels.flatten()\n\n# Save results to CSV\nsubmission = pd.DataFrame({'ID': test_pd.index, 'class' : ['pneumonia' if pred == 1 else 'healthy' for pred in y_pred]})\nsubmission.to_csv('output_submission_eval.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you would like to save the model from working dir to your local machine\nmodel.save('/kaggle/working/checkpoints/model-14-0.07.keras')\n!zip -r /kaggle/working/model-14-0.07.zip /kaggle/working/checkpoints/model-14-0.07.keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}